{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating RAG from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91859\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "c:\\Users\\91859\\Desktop\\rag_scratch\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import fitz\n",
    "from transformers import BertTokenizer,BertModel\n",
    "import re\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model=BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page no:  1\n",
      "Content:  Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeer∗\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Parmar∗\n",
      "Google Research\n",
      "nikip@google.com\n",
      "Jakob Uszkoreit∗\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jones∗\n",
      "Google Research\n",
      "llion@google.com\n",
      "Aidan N. Gomez∗†\n",
      "University of Toronto\n",
      "aidan@cs.toronto.edu\n",
      "Łukasz Kaiser∗\n",
      "Google Brain\n",
      "lukaszkaiser@google.com\n",
      "Illia Polosukhin∗‡\n",
      "illia.polosukhin@gmail.com\n",
      "Abstract\n",
      "The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks that include an encoder and a decoder. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer,\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "entirely. Experiments on two machine translation tasks show these models to\n",
      "be superior in quality while being more parallelizable and requiring significantly\n",
      "less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\n",
      "to-German translation task, improving over the existing best results, including\n",
      "ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\n",
      "our model establishes a new single-model state-of-the-art BLEU score of 41.8 after\n",
      "training for 3.5 days on eight GPUs, a small fraction of the training costs of the\n",
      "best models from the literature. We show that the Transformer generalizes well to\n",
      "other tasks by applying it successfully to English constituency parsing both with\n",
      "large and limited training data.\n",
      "∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\n",
      "the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\n",
      "has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\n",
      "attention and the parameter-free position representation and became the other person involved in nearly every\n",
      "detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\n",
      "tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\n",
      "efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\n",
      "implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\n",
      "our research.\n",
      "†Work performed while at Google Brain.\n",
      "‡Work performed while at Google Research.\n",
      "31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\n",
      "arXiv:1706.03762v7  [cs.CL]  2 Aug 2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_doc(path):\n",
    "    full_text=[]\n",
    "    doc=fitz.open(path)\n",
    "    for page_num in range(len(doc)):\n",
    "        page=doc.load_page(page_num)\n",
    "        text=page.get_text()\n",
    "        full_text.append({\n",
    "        \"page_number\": page_num + 1,\n",
    "        \"text\": text\n",
    "    })\n",
    "    doc.close()\n",
    "    return full_text\n",
    "\n",
    "doc=load_doc(r\"C:\\Users\\91859\\Desktop\\rag_scratch\\sample_pdf.pdf\")\n",
    "\n",
    "print(\"Page no: \",doc[0]['page_number'])\n",
    "print(\"Content: \",doc[0]['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page no:  1\n",
      "Content:  Provided proper attribution is provided, Google hereby grants permission to reproduce the tables and figures in this paper solely for use in journalistic or scholarly works. Attention Is All You Need Ashish Vaswani∗ Google Brain avaswani@google.com Noam Shazeer∗ Google Brain noam@google.com Niki Parmar∗ Google Research nikip@google.com Jakob Uszkoreit∗ Google Research usz@google.com Llion Jones∗ Google Research llion@google.com Aidan N. Gomez∗† University of Toronto aidan@cs.toronto.edu Łukasz Kaiser∗ Google Brain lukaszkaiser@google.com Illia Polosukhin∗‡ illia.polosukhin@gmail.com Abstract The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English- to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data. ∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head attention and the parameter-free position representation and became the other person involved in nearly every detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating our research. †Work performed while at Google Brain. ‡Work performed while at Google Research. 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA. arXiv:1706.03762v7  [cs.CL]  2 Aug 2023 \n"
     ]
    }
   ],
   "source": [
    "def preprocess_doc(doc):\n",
    "    placeholder = \"___PARAGRAPH_BREAK___\"\n",
    "    for page in doc:\n",
    "        page[\"text\"]=re.sub(r'\\n\\d\\n+',r'\\n',page[\"text\"])  #removes page numbers\n",
    "        page[\"text\"]=re.sub(r'(\\n )+',placeholder,page[\"text\"])\n",
    "        page[\"text\"]=re.sub(r'\\n',' ',page[\"text\"])\n",
    "        page[\"text\"]=re.sub(placeholder,'\\n',page[\"text\"])\n",
    "    return doc\n",
    "\n",
    "doc=preprocess_doc(doc)\n",
    "print(\"Page no: \",doc[0]['page_number'])\n",
    "print(\"Content: \",doc[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_text(doc,chunk_size=250,overlap=20): # character based splitting\n",
    "    chunks=[]\n",
    "    page_num=[]\n",
    "    for page in doc:\n",
    "        start=0\n",
    "        while(start< len(page[\"text\"])):\n",
    "            \n",
    "            end=min(start+chunk_size,len(page[\"text\"]))\n",
    "            a=\"\".join(page[\"text\"][start:end+1])\n",
    "            page_num.append(page[\"page_number\"])\n",
    "            start=start+chunk_size-overlap\n",
    "            chunks.append(a)\n",
    "    return chunks,page_num\n",
    "\n",
    "chunks,page_num=split_text(doc)\n",
    "#print(chunks)\n",
    "#print(page_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting by character is not efficient since it may break words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(doc,chunk_size=80,overlap=4):  # word-based splitting\n",
    "    chunks=[]\n",
    "    page_num=[]\n",
    "    for page in doc:\n",
    "        words=page[\"text\"].split()\n",
    "        start=0\n",
    "        while(start<len(words)):\n",
    "            end=min(start+chunk_size,len(words))\n",
    "            a=\" \".join(words[start:end])\n",
    "            page_num.append(page[\"page_number\"])\n",
    "            start=start+chunk_size-overlap\n",
    "            chunks.append(a)\n",
    "    return chunks,page_num\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided proper attribution is provided, Google hereby grants permission to reproduce the tables and figures in this paper solely for use in journalistic or scholarly works. Attention Is All You Need Ashish Vaswani∗ Google Brain avaswani@google.com Noam Shazeer∗ Google Brain noam@google.com Niki Parmar∗ Google Research nikip@google.com Jakob Uszkoreit∗ Google Research usz@google.com Llion Jones∗ Google Research llion@google.com Aidan N. Gomez∗† University of Toronto aidan@cs.toronto.edu Łukasz Kaiser∗ Google Brain lukaszkaiser@google.com Illia Polosukhin∗‡ illia.polosukhin@gmail.com Abstract The dominant sequence transduction models are based on\n",
      "--------------------------------------------------------------------------------\n",
      "models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4\n",
      "--------------------------------------------------------------------------------\n",
      "Our model achieves 28.4 BLEU on the WMT 2014 English- to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to\n",
      "--------------------------------------------------------------------------------\n",
      "[1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 13, 13, 14, 14, 14, 15, 15, 15]\n",
      "No of chunks :  89\n",
      "Length of pages array :  89\n"
     ]
    }
   ],
   "source": [
    "chunks,page_num=split(doc)\n",
    "for i in chunks[0:3]:\n",
    "    print(i)\n",
    "    print(\"--------------------------------------------------------------------------------\")\n",
    "print(page_num)\n",
    "print(\"No of chunks : \", len(chunks))\n",
    "print(\"Length of pages array : \", len(page_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_sent(doc,max_length=150):\n",
    "    chunks=[]\n",
    "    page_num=[]\n",
    "    for page in doc:\n",
    "        sentences = sent_tokenize(page[\"text\"])\n",
    "        current=''\n",
    "        for sent in sentences:\n",
    "            if len(current.split())+len(sent.split()) <max_length:\n",
    "                current+=' '+sent\n",
    "            else:\n",
    "                chunks.append(current)\n",
    "                page_num.append(page[\"page_number\"])\n",
    "                current=sent\n",
    "        if current:\n",
    "            chunks.append(current.strip())\n",
    "            page_num.append(page[\"page_number\"])\n",
    "        \n",
    "    return chunks,page_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Provided proper attribution is provided, Google hereby grants permission to reproduce the tables and figures in this paper solely for use in journalistic or scholarly works. Attention Is All You Need Ashish Vaswani∗ Google Brain avaswani@google.com Noam Shazeer∗ Google Brain noam@google.com Niki Parmar∗ Google Research nikip@google.com Jakob Uszkoreit∗ Google Research usz@google.com Llion Jones∗ Google Research llion@google.com Aidan N. Gomez∗† University of Toronto aidan@cs.toronto.edu Łukasz Kaiser∗ Google Brain lukaszkaiser@google.com Illia Polosukhin∗‡ illia.polosukhin@gmail.com Abstract The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\n",
      "--------------------------------------------------------------------------------\n",
      "Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English- to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data. ∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started the effort to evaluate this idea.\n",
      "--------------------------------------------------------------------------------\n",
      "Ashish, with Illia, designed and implemented the first Transformer models and has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head attention and the parameter-free position representation and became the other person involved in nearly every detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating our research. †Work performed while at Google Brain. ‡Work performed while at Google Research. 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA. arXiv:1706.03762v7  [cs.CL]  2 Aug 2023\n",
      "--------------------------------------------------------------------------------\n",
      "[1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 8, 8, 8, 8, 9, 9, 9, 9, 9, 10, 10, 10, 10, 11, 11, 11, 12, 12, 12, 12, 13, 14, 14, 15, 15]\n",
      "No of chunks :  50\n",
      "Length of pages array :  50\n"
     ]
    }
   ],
   "source": [
    "chunks,page_num=split_by_sent(doc)\n",
    "for i in chunks[0:3]:\n",
    "    print(i)\n",
    "    print(\"--------------------------------------------------------------------------------\")\n",
    "print(page_num)\n",
    "print(\"No of chunks : \", len(chunks))\n",
    "print(\"Length of pages array : \", len(page_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens=tokenizer.batch_encode_plus(chunks,add_special_tokens=True,padding=True,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] provided proper attribution is provided, google hereby grants permission to reproduce the tables and figures in this paper solely for use in journalistic or scholarly works. attention is all you need ashish vaswani∗ google brain avaswani @ google. com noam shazeer∗ google brain noam @ google. com niki parmar∗ google research nikip @ google. com jakob uszkoreit∗ google research usz @ google. com llion jones∗ google research llion @ google. com aidan n. gomez∗ † university of toronto aidan @ cs. toronto. edu łukasz kaiser∗ google brain lukaszkaiser @ google. com illia polosukhin∗ ‡ illia. polosukhin @ gmail. com abstract the dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. the best performing models also connect the encoder and decoder through an attention mechanism. we propose a new simple network architecture, the transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "text=tokenizer.decode(tokens['input_ids'][0])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=torch.tensor(tokens[\"input_ids\"]).to(DEVICE)\n",
    "mask=torch.tensor(tokens[\"attention_mask\"]).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 345, 768])\n"
     ]
    }
   ],
   "source": [
    "id_tensor = input_ids[0].unsqueeze(0)  # Add batch dim\n",
    "mask_tensor = mask[0].unsqueeze(0)   \n",
    "out= bert_model(input_ids=id_tensor,attention_mask= mask_tensor)[0]\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.modeling_bert.BertModel'>\n"
     ]
    }
   ],
   "source": [
    "def mean_embedding(bert_model,input_ids,attention_masks):\n",
    "    mean_emb=[]\n",
    "    print(type(bert_model))\n",
    "    for id,mask in zip(input_ids,attention_masks):\n",
    "        id=id.unsqueeze(0)\n",
    "        mask=mask.unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            emb=bert_model(id,mask)[0].squeeze(0)\n",
    "\n",
    "            valid_mask=mask[0]==1\n",
    "            valid_emb=emb[valid_mask,:]\n",
    "            mean_embedding = valid_emb.mean(dim=0)\n",
    "\n",
    "            mean_emb.append(mean_embedding.unsqueeze(0))\n",
    "    aggregated_mean_emb=torch.cat(mean_emb)\n",
    "    return aggregated_mean_emb\n",
    "            \n",
    "            \n",
    "aggr_mean_emb=mean_embedding(bert_model,input_ids,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggr_mean_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing in faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_aggr_mean_emb=aggr_mean_emb.cpu().numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "(50, 768)\n"
     ]
    }
   ],
   "source": [
    "print(np_aggr_mean_emb.dtype)\n",
    "print(np_aggr_mean_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension = 768  \n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(np_aggr_mean_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"Explain the encoder and decoder stacks of transformers\"\n",
    "query_tokens=tokenizer.encode(query,add_special_tokens=True,return_tensors='pt')\n",
    "query_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of vector before taking mean :  torch.Size([13, 768])\n",
      "Shape of vector after taking mean :  torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query_emb=bert_model(query_tokens)[0].squeeze(0)\n",
    "print(\"Shape of vector before taking mean : \",query_emb.shape)\n",
    "query_emb=query_emb.mean(dim=0).unsqueeze(0)\n",
    "print(\"Shape of vector after taking mean : \",query_emb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices: [[ 8  3 15 19 16 28 14]]\n",
      "Distances: [[47.394146 49.032997 49.158653 49.342785 49.409195 49.418396 49.83879 ]]\n"
     ]
    }
   ],
   "source": [
    "query_emb_np=query_emb.cpu().detach().numpy().astype('float32')\n",
    "D,I=index.search(query_emb_np,k=7)\n",
    "print(\"Indices:\", I)\n",
    "print(\"Distances:\", D)\n",
    "retrieved_chunks=[]\n",
    "retrieved_pages=[]\n",
    "for i in I[0]:\n",
    "    #print(\"CHUNK : \",chunks[i])\n",
    "    #print(\"PAGE_NO: \",page_num[i])\n",
    "    retrieved_chunks.append(chunks[i])\n",
    "    retrieved_pages.append(page_num[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function that performs tasks we have done till now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_chunks(query,chunks,page_num):\n",
    "    query_tokens=tokenizer.encode(query,add_special_tokens=True,return_tensors='pt')\n",
    "    query_emb=bert_model(query_tokens)[0].squeeze(0)\n",
    "    query_emb=query_emb.mean(dim=0).unsqueeze(0)\n",
    "    query_emb_np=query_emb.cpu().detach().numpy().astype('float32')\n",
    "    D,I=index.search(query_emb_np,k=7)\n",
    "    retrieved_chunks=[]\n",
    "    retrieved_pages=[]\n",
    "    for i in I[0]:\n",
    "        retrieved_chunks.append(chunks[i])\n",
    "        retrieved_pages.append(page_num[i])\n",
    "    return retrieved_chunks,retrieved_pages\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ans(query,chunks,page_num):\n",
    "    \n",
    "    context=\"Context: \"\n",
    "    for i,(chunk,page) in enumerate(zip(chunks,page_num)):\n",
    "        context+=f\"\\nChunk {i}: {chunk}\\n page of chunk {i} is : {page}\"\n",
    "\n",
    "    prompt=f\"\"\"You are a helpfull assistant. Your task is to answer the question based on the given context and their corresponding page numbers.\n",
    "    - Cite relevant page numbers to support your answer, but group citations logically rather than repeating them after every sentence.\n",
    "    - When multiple sentences refer to the same context, place the page number once at the end of the related section.\n",
    "    - Provide detailed and accurate explanations wherever applicable.\n",
    "    - Do not make up answer if the answer is not found in context.\n",
    "    {context}\n",
    "    Question:\n",
    "    {query}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
    "        generation_config = genai.types.GenerationConfig(temperature=0.7,max_output_tokens=1024)\n",
    "        response=model.generate_content(prompt, generation_config=generation_config)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(\"Error occured : \",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result=generate_ans(query,retrieved_chunks,retrieved_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Transformer's encoder consists of a stack of six identical layers (N=6).  Each layer contains two sub-layers: a multi-head self-attention mechanism and a position-wise fully connected feed-forward network.  A residual connection and layer normalization are applied around each sub-layer, with the output of each sub-layer being LayerNorm(x + Sublayer(x)).  All sub-layers and embedding layers output a dimension of dmodel = 512 to facilitate these residual connections. (page 3)\n",
      "\n",
      "The decoder also uses stacked layers,  and similarly to the encoder, utilizes self-attention layers.  However, to maintain the auto-regressive property, a masking mechanism prevents leftward information flow within the scaled dot-product attention. (page 5)  In addition to self-attention, both the encoder and decoder layers include a fully connected feed-forward network applied identically to each position,  consisting of two linear transformations with a ReLU activation in between. (page 5)  The encoder-decoder attention layers allow each position in the decoder to attend to all positions in the encoder output. (page 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the decoder, self-attention layers allow each position to attend to all positions in the decoder up to and including that position.  To maintain the auto-regressive property, leftward information flow is prevented by masking out (setting to −∞) values in the softmax input that correspond to illegal connections. (page 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query=\"Explain the working of self attention layer in decoder\"\n",
    "c,p=retrieve_chunks(query,chunks,page_num)\n",
    "result=generate_ans(query,c,p)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvements that can be made in future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Better text splitting\n",
    "* Generating multiple queries from user query\n",
    "* Reranking chunks after retrieval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
